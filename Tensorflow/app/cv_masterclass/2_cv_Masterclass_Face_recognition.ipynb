{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fM29c2T7_e5V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['subject01.centerlight', 'subject01.glasses', 'subject01.happy', 'subject01.leftlight', 'subject01.noglasses', 'subject01.normal', 'subject01.rightlight', 'subject01.sad', 'subject01.sleepy', 'subject01.surprised', 'subject01.wink', 'subject02.centerlight', 'subject02.glasses', 'subject02.happy', 'subject02.leftlight', 'subject02.normal', 'subject02.rightlight', 'subject02.sad', 'subject02.sleepy', 'subject02.surprised', 'subject02.wink', 'subject03.centerlight', 'subject03.glasses', 'subject03.happy', 'subject03.leftlight', 'subject03.noglasses', 'subject03.normal', 'subject03.rightlight', 'subject03.sad', 'subject03.sleepy', 'subject03.surprised', 'subject04.centerlight', 'subject04.glasses', 'subject04.happy', 'subject04.leftlight', 'subject04.noglasses', 'subject04.normal', 'subject04.rightlight', 'subject04.sad', 'subject04.sleepy', 'subject04.surprised', 'subject04.wink', 'subject05.centerlight', 'subject05.glasses', 'subject05.happy', 'subject05.leftlight', 'subject05.noglasses', 'subject05.rightlight', 'subject05.sad', 'subject05.sleepy', 'subject05.surprised', 'subject05.wink', 'subject06.centerlight', 'subject06.glasses', 'subject06.happy', 'subject06.leftlight', 'subject06.noglasses', 'subject06.normal', 'subject06.rightlight', 'subject06.sad', 'subject06.sleepy', 'subject06.surprised', 'subject06.wink', 'subject02.noglasses', 'subject03.wink', 'subject05.normal', 'subject07.centerlight', 'subject08.rightlight', 'subject10.glasses', 'subject11.sad', 'subject13.happy', 'subject07.glasses', 'subject07.happy', 'subject07.leftlight', 'subject07.noglasses', 'subject07.normal', 'subject07.rightlight', 'subject07.sad', 'subject07.sleepy', 'subject07.surprised', 'subject07.wink', 'subject08.centerlight', 'subject08.glasses', 'subject08.happy', 'subject08.leftlight', 'subject08.noglasses', 'subject08.normal', 'subject08.sad', 'subject08.sleepy', 'subject08.surprised', 'subject08.wink', 'subject09.centerlight', 'subject09.glasses', 'subject09.happy', 'subject09.leftlight', 'subject09.noglasses', 'subject09.normal', 'subject09.rightlight', 'subject09.sad', 'subject09.sleepy', 'subject09.surprised', 'subject09.wink', 'subject10.centerlight', 'subject10.happy', 'subject10.leftlight', 'subject10.noglasses', 'subject10.normal', 'subject10.rightlight', 'subject10.sad', 'subject10.sleepy', 'subject10.surprised', 'subject10.wink', 'subject11.centerlight', 'subject11.glasses', 'subject11.happy', 'subject11.leftlight', 'subject11.noglasses', 'subject11.normal', 'subject11.rightlight', 'subject11.sleepy', 'subject11.surprised', 'subject11.wink', 'subject12.centerlight', 'subject12.glasses', 'subject12.happy', 'subject12.leftlight', 'subject12.noglasses', 'subject12.normal', 'subject12.rightlight', 'subject12.sad', 'subject12.sleepy', 'subject12.surprised', 'subject12.wink', 'subject13.centerlight', 'subject13.glasses', 'subject13.leftlight', 'subject13.noglasses', 'subject13.normal', 'subject13.rightlight', 'subject13.sad', 'subject13.sleepy', 'subject13.surprised', 'subject13.wink', 'subject14.centerlight', 'subject14.glasses', 'subject14.happy', 'subject14.leftlight', 'subject14.noglasses', 'subject14.normal', 'subject14.rightlight', 'subject14.sad', 'subject14.sleepy', 'subject14.surprised', 'subject14.wink', 'subject15.centerlight', 'subject15.glasses', 'subject15.happy', 'subject15.leftlight', 'subject15.noglasses', 'subject15.normal', 'subject15.rightlight', 'subject15.sad', 'subject15.sleepy', 'subject15.surprised', 'subject15.wink']\n"
          ]
        }
      ],
      "source": [
        "# Face recognition\n",
        "print(os.listdir(\"./data/dataset_yalefaces/\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T_6MUlv2Cfvg"
      },
      "outputs": [],
      "source": [
        "def get_image_data():\n",
        "  paths = [os.path.join('./data/dataset_yalefaces/', f) for f in os.listdir('./data/dataset_yalefaces/')]\n",
        "  #print(paths)\n",
        "  faces = []\n",
        "  ids = []\n",
        "  for path in paths:\n",
        "    #print(path)\n",
        "    image = Image.open(path).convert('L')\n",
        "    #print(type(image))\n",
        "    image_np = np.array(image, 'uint8')\n",
        "    #print(type(image_np))\n",
        "    id = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
        "    #print(id)\n",
        "    ids.append(id)\n",
        "    faces.append(image_np)\n",
        "\n",
        "  return np.array(ids), faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7kjNb0PaC6-2"
      },
      "outputs": [],
      "source": [
        "ids, faces = get_image_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1SKHBy2GFzl",
        "outputId": "ddd2838c-c60e-411f-81de-b7f8fefe9cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
              "        2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
              "        4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
              "        5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  2,  3,  5,  7,  8,\n",
              "       10, 11, 13,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
              "        8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13,\n",
              "       13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhlCn9pZGJJE",
        "outputId": "e1e57716-f260-4254-9a3d-adb0c7e6a03e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(165, 165)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ids), len(faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvF2_Tv_GMBH",
        "outputId": "b5077b69-8e21-46c0-e471-45b55b835d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[130, 130, 130, ..., 255, 255, 255],\n",
              "        [255, 255, 255, ..., 255, 255, 255],\n",
              "        [255, 255, 255, ..., 255, 255, 255],\n",
              "        ...,\n",
              "        [255, 255, 255, ..., 255, 255, 255],\n",
              "        [255, 255, 255, ..., 255, 255, 255],\n",
              "        [ 68,  68,  68, ...,  68,  68,  68]], dtype=uint8),\n",
              " (243, 320))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faces[0], faces[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl-JouHAGwbE",
        "outputId": "763e16fc-a61a-431d-cbe6-7ea9f887bb0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77760"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "243 * 320"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRuJuHRLvcmW"
      },
      "source": [
        "### Training the LBPH classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP_bE2tWLSz4",
        "outputId": "15ffba70-0a4e-45bd-c19d-62eedeffaab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "8 * 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTHLAAnTLBfY"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
            "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
            "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
            "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
          ]
        }
      ],
      "source": [
        "# threshold: 1.7976931348623157e+308\n",
        "# radius: 1\n",
        "# neighbors: 8\n",
        "# grid_x: 8\n",
        "# grid_y: 8\n",
        "\n",
        "lbph_classifier = cv2.face.LBPHFaceRecognizer(radius = 4, neighbors=14, grid_x = 9, grid_y = 9)\n",
        "#lbph_classifier.train(faces, ids)\n",
        "lbph_classifier.write('lbph_classifier.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(help(cv2.face))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37itAmjd1AGm"
      },
      "source": [
        "### Recognizing faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ3srgyaMeUs"
      },
      "outputs": [],
      "source": [
        "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_face_classifier.read('/content/lbph_classifier.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUcev8JwMyrx"
      },
      "outputs": [],
      "source": [
        "test_image = '/content/yalefaces/test/subject10.sad.gif'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxNNQ6-WM_Ld",
        "outputId": "d79efab0-c036-47e7-b62b-481cdccdf508"
      },
      "outputs": [],
      "source": [
        "image = Image.open(test_image).convert('L')\n",
        "image_np = np.array(image, 'uint8')\n",
        "image_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUGkF1Q4Ninp",
        "outputId": "0f314cf0-9ee2-4c56-b4c8-96d1ffbacb9f"
      },
      "outputs": [],
      "source": [
        "image_np.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut_l-QSNNn7t",
        "outputId": "d362a102-30c4-443a-9ee1-a69714d8baf4"
      },
      "outputs": [],
      "source": [
        "prediction = lbph_face_classifier.predict(image_np)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22XfWA6bOiox",
        "outputId": "9b91a4d7-f665-4018-eb80-6ec38bb7d27e"
      },
      "outputs": [],
      "source": [
        "prediction[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb9T5wF2N71g",
        "outputId": "3bae3cc2-6ae6-4c76-a382-c878cdf4fcf0"
      },
      "outputs": [],
      "source": [
        "expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject', ''))\n",
        "expected_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "IcN3jt5UOUJ9",
        "outputId": "963ea143-d548-4cbc-b413-7da8b873c4f1"
      },
      "outputs": [],
      "source": [
        "cv2.putText(image_np, 'Pred: ' + str(prediction[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "cv2.putText(image_np, 'Exp: ' + str(expected_output), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "cv2_imshow(image_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eyUv8l00oAt"
      },
      "source": [
        "### Evaluating the face classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJcCdWm7P33p"
      },
      "outputs": [],
      "source": [
        "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "for path in paths:\n",
        "  #print(path)\n",
        "  image = Image.open(path).convert('L')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
        "  expected_output = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
        "\n",
        "  predictions.append(prediction)\n",
        "  expected_outputs.append(expected_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n60u0NEEQ8kp",
        "outputId": "822ab039-c42b-42b5-ce48-247c2bb737a1"
      },
      "outputs": [],
      "source": [
        "type(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOT1AMkhRBmV"
      },
      "outputs": [],
      "source": [
        "predictions = np.array(predictions)\n",
        "expected_outputs = np.array(expected_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVlkm6hkRIrJ",
        "outputId": "799da9f8-44c7-4bf0-8240-98b77c2c59c0"
      },
      "outputs": [],
      "source": [
        "type(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVQgB2ScRLmx",
        "outputId": "f8d06c3b-4550-4079-fa4f-df53dc87530a"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8PhkMhxRSDv",
        "outputId": "44aa9b58-2f05-4491-bf47-e4711efb0ee3"
      },
      "outputs": [],
      "source": [
        "expected_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brDGncBPRjKf",
        "outputId": "341a46df-8133-4a2f-85da-72b7619ce92e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(expected_outputs, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srcIm3MrR5xb",
        "outputId": "dfc384da-9c9c-4a5b-a0b7-a02abe8c5f30"
      },
      "outputs": [],
      "source": [
        "len(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pywl22gASMPh",
        "outputId": "0e04e16d-851d-4116-b734-dabaea70aceb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(expected_outputs, predictions)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "UIModdwtSVm9",
        "outputId": "ccf6c7d6-2939-4c28-f758-3e45793e96f6"
      },
      "outputs": [],
      "source": [
        "import seaborn\n",
        "seaborn.heatmap(cm, annot=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw1aTLB6SdP2"
      },
      "source": [
        "## Dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7svnaxog97Ss"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO_I5o6RKpFt"
      },
      "source": [
        "### Detecting facial points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYyZCTG8-Kxz"
      },
      "outputs": [],
      "source": [
        "face_detector = dlib.get_frontal_face_detector()\n",
        "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "XlywU7Y7_bsi",
        "outputId": "6a7d02d6-16dc-43e4-faf6-d729b818fcbd"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Images/people2.jpg')\n",
        "face_detection = face_detector(image, 1)\n",
        "for face in face_detection:\n",
        "  points = points_detector(image, face)\n",
        "  for point in points.parts():\n",
        "    cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)\n",
        "\n",
        "  #print(points.parts())\n",
        "  #print(len(points.parts()))\n",
        "\n",
        "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
        "  cv2.rectangle(image, (l, t), (r, b), (0,255,255), 2)\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhZ2dDNe54Oe"
      },
      "source": [
        "### Detecting facial descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBunTbwvEbBD"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJBYZDULEjN4"
      },
      "outputs": [],
      "source": [
        "# Resnet: https://arxiv.org/abs/1512.03385\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')\n",
        "face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Weights/dlib_face_recognition_resnet_model_v1.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DNqWwugGqQM"
      },
      "outputs": [],
      "source": [
        "index = {}\n",
        "idx = 0\n",
        "face_descriptors = None\n",
        "\n",
        "paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
        "for path in paths:\n",
        "  #print(path)\n",
        "  image = Image.open(path).convert('RGB')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  face_detection = face_detector(image_np, 1)\n",
        "  for face in face_detection:\n",
        "    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
        "    cv2.rectangle(image_np, (l, t), (r, b), (0, 0, 255), 2)\n",
        "\n",
        "    points = points_detector(image_np, face)\n",
        "    for point in points.parts():\n",
        "      cv2.circle(image_np, (point.x, point.y), 2, (0, 255, 0), 1)\n",
        "\n",
        "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
        "    #print(type(face_descriptor))\n",
        "    #print(len(face_descriptor))\n",
        "    #print(face_descriptor)\n",
        "    face_descriptor = [f for f in face_descriptor]\n",
        "    #print(face_descriptor)\n",
        "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
        "    #print(face_descriptor)\n",
        "    #print(face_descriptor.shape)\n",
        "    face_descriptor = face_descriptor[np.newaxis, :]\n",
        "    #print(face_descriptor.shape)\n",
        "    #print(face_descriptor)\n",
        "\n",
        "    if face_descriptors is None:\n",
        "      face_descriptors = face_descriptor\n",
        "    else:\n",
        "      face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
        "\n",
        "    index[idx] = path\n",
        "    idx += 1\n",
        "  #cv2_imshow(image_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF8Ed2izODzS",
        "outputId": "44bf858c-6f87-46c0-c35f-21479d4ab654"
      },
      "outputs": [],
      "source": [
        "face_descriptors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynYHDQdwOarV",
        "outputId": "3a386852-295d-4512-f12a-3698463ab95f"
      },
      "outputs": [],
      "source": [
        "face_descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MfqbVIVOhga",
        "outputId": "968baaa6-1bea-4964-a18b-78286f34b1cb"
      },
      "outputs": [],
      "source": [
        "len(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsl-LZSBOrvc",
        "outputId": "fedcd588-b0c9-4330-96bb-691bd192fcd5"
      },
      "outputs": [],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLaqtBb57EN"
      },
      "source": [
        "### Calculating the distance between faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A0R4JO2QcC6",
        "outputId": "f8d0225f-3cb2-4860-b246-d918fc6adde2"
      },
      "outputs": [],
      "source": [
        "face_descriptors[131]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx4-hF3yQNjK",
        "outputId": "6030ee64-c18e-47d9-c89f-737b2466bf48"
      },
      "outputs": [],
      "source": [
        "# https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html#numpy.linalg.norm\n",
        "np.linalg.norm(face_descriptors[131] - face_descriptors[131])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0WesKaXRG_f",
        "outputId": "2d3bb5b2-0cd0-4e01-e3a2-1e03128bde16"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[130])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCfcrZWbRk_h",
        "outputId": "fd296c4c-375d-441d-bdfc-5b452dde2e61"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[129])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf5XCjjtSAwy",
        "outputId": "26fb095d-0790-42f4-916a-93dcfab9636b"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(face_descriptors[131] - face_descriptors[128])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR71E6gdShBB",
        "outputId": "49316d61-00f0-41fa-c541-272dab8eeed3"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(face_descriptors[0] - face_descriptors, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5pRuXBfS4yF",
        "outputId": "d50deb86-75f8-4e4a-87a9-19e88e2bbc20"
      },
      "outputs": [],
      "source": [
        "np.argmin(np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH1ZwQKXTxLS",
        "outputId": "0b430c5e-4fb7-465c-da41-1451b2b753c3"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(face_descriptors[0] - face_descriptors[1:], axis = 1)[91]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_rUY0dO5-J0"
      },
      "source": [
        "### Detecting faces with Dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E-034wqtVHVz",
        "outputId": "2eab4bd7-9316-4072-8c02-c262ddd170b4"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5\n",
        "predictions = []\n",
        "expected_outputs = []\n",
        "\n",
        "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
        "for path in paths:\n",
        "  image = Image.open(path).convert('RGB')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  face_detection = face_detector(image_np, 1)\n",
        "  for face in face_detection:\n",
        "    points = points_detector(image_np, face)\n",
        "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
        "    face_descriptor = [f for f in face_descriptor]\n",
        "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
        "    face_descriptor = face_descriptor[np.newaxis, :]\n",
        "\n",
        "    distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n",
        "    min_index = np.argmin(distances)\n",
        "    min_distance = distances[min_index]\n",
        "    if min_distance <= threshold:\n",
        "      name_pred = int(os.path.split(index[min_index])[1].split('.')[0].replace('subject', ''))\n",
        "    else:\n",
        "      name_pred = 'Not identified'\n",
        "\n",
        "    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
        "\n",
        "    predictions.append(name_pred)\n",
        "    expected_outputs.append(name_real)\n",
        "\n",
        "    cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "    cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "\n",
        "\n",
        "  cv2_imshow(image_np)\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "expected_outputs = np.array(expected_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT-FE84fajb1",
        "outputId": "d7a75093-b4c4-46c1-86c7-6e18e3f2b9e3"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPdfJRmQalKR",
        "outputId": "dd348151-1b2d-47fb-dbb1-f2b353447fbf"
      },
      "outputs": [],
      "source": [
        "expected_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVdGI3xoatoE",
        "outputId": "22743577-34e5-4dc5-a475-d13c74552ab4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(expected_outputs, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_7ri5zj6Alb"
      },
      "source": [
        "## Homework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k4LA3AZbWd3",
        "outputId": "207aee4e-710d-449d-f62f-f2a021ab7c7c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNtcCZURbUhD"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "path = '/content/drive/MyDrive/Cursos - recursos/Computer Vision Masterclass/Datasets/jones_gabriel.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode='r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBLCIuBNbY0S"
      },
      "outputs": [],
      "source": [
        "def get_image_data():\n",
        "  paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
        "  faces = []\n",
        "  ids = []\n",
        "  for path in paths:\n",
        "    image = Image.open(path).convert('L')\n",
        "    image_np = np.array(image, 'uint8')\n",
        "    id = int(path.split('.')[1])\n",
        "\n",
        "    ids.append(id)\n",
        "    faces.append(image_np)\n",
        "\n",
        "  return np.array(ids), faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgoUfIboba2L"
      },
      "outputs": [],
      "source": [
        "ids, faces = get_image_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm7Rm6dnbc7A"
      },
      "outputs": [],
      "source": [
        "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_classifier.train(faces, ids)\n",
        "lbph_classifier.write('lbph_classifier.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sQvshSRbfBl"
      },
      "outputs": [],
      "source": [
        "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_face_classifier.read('/content/lbph_classifier.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJMfLHRHbhBD",
        "outputId": "a58305a4-7761-4dbd-f518-f4c761c60779"
      },
      "outputs": [],
      "source": [
        "image = Image.open('/content/jones_gabriel/person.1.1.jpg')\n",
        "image.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TgFA9zScblF3",
        "outputId": "a3d90f91-6d53-4ded-9ba3-d81b7b28579b"
      },
      "outputs": [],
      "source": [
        "paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
        "for path in paths:\n",
        "  image = Image.open(path).convert('L')\n",
        "  image_np = np.array(image, 'uint8')\n",
        "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
        "  expected_output = int(path.split('.')[1])\n",
        "\n",
        "  cv2.putText(image_np, 'Pred: ' + str(prediction), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "  cv2.putText(image_np, 'Exp: ' + str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
        "  cv2_imshow(image_np)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
