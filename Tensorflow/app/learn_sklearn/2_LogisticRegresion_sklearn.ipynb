{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing # One-hot-Encoder y LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import opendatasets as od # Download of kaggle od.download(url)\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['font.size'] = 8\n",
    "plt.rcParams['figure.figsize'] = (4, 3)\n",
    "plt.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/weatherAUS.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row, si existe datos faltantes de 2 variables\n",
    "data.dropna(subset=[\"RainToday\",\"RainTomorrow\"], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x=\"Location\", title=\"Location vs Rainy Days\", color=\"RainToday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x=\"Temp3pm\", title=\"Temperature at 3pm vs Rain Tomorrow\", color=\"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x=\"RainTomorrow\", color=\"RainToday\", title=\"Rain Tomorrow vs Rain Today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data.sample(2000), title=\"Min temp vs Max Temp\", x=\"MinTemp\", y=\"MaxTemp\", color=\"RainToday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data.sample(2000), title=\"Temp 3pm vs Humidity\", x=\"Temp3pm\", y=\"Humidity3pm\", color=\"RainTomorrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_val_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)\n",
    "\n",
    "print('train_df.shape :', train_df.shape)\n",
    "print('val_df.shape :', val_df.shape)\n",
    "print('test_df.shape :', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.to_datetime(data.Date).dt.year\n",
    "\n",
    "train_df = data[year < 2015]\n",
    "val_df = data[year == 2015]\n",
    "test_df = data[year > 2015]\n",
    "\n",
    "print(\"train shape: \", train_df.shape)\n",
    "print(\"val shape: \", val_df.shape)\n",
    "print(\"test shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"No of Rows per Year\")\n",
    "sns.countplot(x=pd.to_datetime(data.Date).dt.year, hue=year);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying input and target columns\n",
    "input_cols = list(train_df.columns)[1:-1]\n",
    "target_cols = \"RainTomorrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input cols: \", input_cols)\n",
    "print(\"target cols: \", target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train_df[input_cols].copy()\n",
    "train_targets = train_df[target_cols].copy()\n",
    "\n",
    "val_inputs = val_df[input_cols].copy()\n",
    "val_targets = val_df[target_cols].copy()\n",
    "\n",
    "test_inputs = test_df[input_cols].copy()\n",
    "test_targets = test_df[target_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_cols = train_inputs.select_dtypes(\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Missing Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "data[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(imputer.statistics_) # is strategy=\"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[num_cols] = imputer.transform(train_inputs[num_cols])\n",
    "val_inputs[num_cols] = imputer.transform(val_inputs[num_cols])\n",
    "test_inputs[num_cols] = imputer.transform(test_inputs[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Numeric Features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(scaler.data_min_) # is value min for variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler transform data train, val & test\n",
    "train_inputs[num_cols] = scaler.transform(train_inputs[num_cols])\n",
    "val_inputs[num_cols] = scaler.transform(val_inputs[num_cols])\n",
    "test_inputs[num_cols] = scaler.transform(test_inputs[num_cols])\n",
    "\n",
    "train_inputs[num_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoder.fit(data[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = list(encoder.get_feature_names_out(cat_cols))\n",
    "print(encoded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[encoded_cols] = encoder.transform(train_inputs[cat_cols])\n",
    "val_inputs[encoded_cols] = encoder.transform(val_inputs[cat_cols])\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs[cat_cols])\n",
    "#pd.set_option('display.max_columns', None) # muestra mensaje de warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_inputs:', train_inputs.shape)\n",
    "print('train_targets:', train_targets.shape)\n",
    "print('val_inputs:', val_inputs.shape)\n",
    "print('val_targets:', val_targets.shape)\n",
    "print('test_inputs:', test_inputs.shape)\n",
    "print('test_targets:', test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "model.fit(train_inputs[num_cols + encoded_cols], train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions and evaluating the model\n",
    "x_train = train_inputs[num_cols + encoded_cols]\n",
    "x_val = val_inputs[num_cols + encoded_cols]\n",
    "x_test= test_inputs[num_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(x_train)\n",
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = model.predict_proba(x_train)\n",
    "train_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(train_targets, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(train_targets, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(train_targets, train_preds, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(inputs, targets, name=''):\n",
    "    preds = model.predict(inputs)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, preds)\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    \n",
    "    cf = confusion_matrix(targets, preds, normalize='true')\n",
    "    plt.figure()\n",
    "    sns.heatmap(cf, annot=True)\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Target')\n",
    "    plt.title('{} Confusion Matrix'.format(name));\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(x_train, train_targets, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(x_val, val_targets, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(x_test, test_targets, 'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on a single input\n",
    "\n",
    "new_input = {'Date': '2021-06-19',\n",
    "             'Location': 'Katherine',\n",
    "             'MinTemp': 23.2,\n",
    "             'MaxTemp': 33.2,\n",
    "             'Rainfall': 10.2,\n",
    "             'Evaporation': 4.2,\n",
    "             'Sunshine': np.nan,\n",
    "             'WindGustDir': 'NNW',\n",
    "             'WindGustSpeed': 52.0,\n",
    "             'WindDir9am': 'NW',\n",
    "             'WindDir3pm': 'NNE',\n",
    "             'WindSpeed9am': 13.0,\n",
    "             'WindSpeed3pm': 20.0,\n",
    "             'Humidity9am': 89.0,\n",
    "             'Humidity3pm': 58.0,\n",
    "             'Pressure9am': 1004.8,\n",
    "             'Pressure3pm': 1001.5,\n",
    "             'Cloud9am': 8.0,\n",
    "             'Cloud3pm': 5.0,\n",
    "             'Temp9am': 25.7,\n",
    "             'Temp3pm': 33.0,\n",
    "             'RainToday': 'Yes'}\n",
    "\n",
    "new_input_df = pd.DataFrame([new_input])\n",
    "new_input_df[num_cols] = imputer.transform(new_input_df[num_cols])\n",
    "new_input_df[num_cols] = scaler.transform(new_input_df[num_cols])\n",
    "new_input_df[encoded_cols] = encoder.transform(new_input_df[cat_cols])\n",
    "\n",
    "x_new_input = new_input_df[num_cols + encoded_cols]\n",
    "prediction = model.predict(x_new_input)[0]\n",
    "prob = model.predict_proba(x_new_input)[0]\n",
    "\n",
    "print(\"Prediction is: \", prediction)\n",
    "print(\"Probability is: \", prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input(single_input):\n",
    "    input_df = pd.DataFrame([single_input])\n",
    "    input_df[num_cols] = imputer.transform(input_df[num_cols])\n",
    "    input_df[num_cols] = scaler.transform(input_df[num_cols])\n",
    "    input_df[encoded_cols] = encoder.transform(input_df[cat_cols])\n",
    "    X_input = input_df[num_cols + encoded_cols]\n",
    "    pred = model.predict(X_input)[0]\n",
    "    prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)]\n",
    "    return pred, prob\n",
    "\n",
    "predict_input(new_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
